{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8fe567cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(747, 31)\n",
      "(250, 31)\n",
      "(747,)\n",
      "(250,)\n"
     ]
    }
   ],
   "source": [
    "# 1. Import pandas\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from utils import feature_transform \n",
    "from sklearn.metrics.pairwise import rbf_kernel\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 2. Load the saved CSVs\n",
    "X_train = pd.read_csv('X_train.csv')\n",
    "X_test = pd.read_csv('X_test.csv')\n",
    "y_train = pd.read_csv('y_train.csv')\n",
    "y_test = pd.read_csv('y_test.csv')\n",
    "\n",
    "# 3. (Optional but important) - if y_train and y_test are DataFrames, squeeze to make them Series\n",
    "y_train = y_train.squeeze()\n",
    "y_test = y_test.squeeze()\n",
    "\n",
    "# 4. Verify shapes\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3504eb97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q18 - w_logreg:  [[ 0.18458759 -0.08049333  0.65967944  0.17160387 -0.1336652   0.09562481\n",
      "   0.00763028  0.10202784 -1.44520027  1.47488404  0.15478932  0.66014534\n",
      "  -2.0635181   1.67083045 -0.52909525 -1.13490081 -0.92120242 -0.35406633\n",
      "  -0.4769137  -0.13604357  0.02723772 -0.02723772  0.09473924 -0.014406\n",
      "   0.03339916 -0.72611491  0.03901717  0.          0.03613793 -0.03329378\n",
      "  -0.017095  ]]\n",
      "Q18 - intercept_logreg:  [-1.81823517]\n",
      "Q19 - Accuracy on training data = 0.788000\n",
      "Q20 - prec:  0.6793103448275862\n",
      "Q20 - recal:  0.2398052343274498\n",
      "Q20 - fscore:  0.35447593342330186\n"
     ]
    }
   ],
   "source": [
    "logreg = linear_model.LogisticRegression(penalty = None)\n",
    "logreg.fit(X_train, y_train)\n",
    "w_logreg = logreg.coef_\n",
    "intercept_logreg = logreg.intercept_\n",
    "print('Q18 - w_logreg: ', w_logreg)\n",
    "print('Q18 - intercept_logreg: ', intercept_logreg)\n",
    "y_hat_logreg = logreg.predict(X_test)\n",
    "\n",
    "# Find the accuracy achieved on test set using logreg.score and y_test \n",
    "acc_logreg = logreg.score(X_test, y_test)\n",
    "\n",
    "print(\"Q19 - Accuracy on training data = %f\" % acc_logreg)\n",
    "\n",
    "# TODO Q20\n",
    "\n",
    "\n",
    "print('Q20 - prec: ', prec)\n",
    "print('Q20 - recal: ', recal)\n",
    "print('Q20 - fscore: ', fscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e47a21e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def run_logistic_regression(X_train, X_test, y_train, y_test, \n",
    "                            regularization_value=1.0, \n",
    "                            feature_method=None,\n",
    "                            degree=2, \n",
    "                            n_components=2, \n",
    "                            gamma=None):\n",
    "    \"\"\"\n",
    "    Runs logistic regression with optional feature transformation.\n",
    "\n",
    "    feature_method: None, 'pca', 'polynomial', or 'rbf'\n",
    "    \"\"\"\n",
    "\n",
    "    # 1) PCA\n",
    "    if feature_method == 'pca':\n",
    "        pca = PCA(n_components=n_components)\n",
    "        X_train = pca.fit_transform(X_train)\n",
    "        X_test  = pca.transform(X_test)\n",
    "\n",
    "    # 2) Polynomial\n",
    "    elif feature_method == 'polynomial':\n",
    "        poly = PolynomialFeatures(degree=degree, include_bias=False)\n",
    "        X_train = poly.fit_transform(X_train)\n",
    "        X_test  = poly.transform(X_test)\n",
    "\n",
    "    # 3) RBF kernel\n",
    "    elif feature_method == 'rbf':\n",
    "        # first compute the train–train kernel\n",
    "        K_train = rbf_kernel(X_train, X_train, gamma=gamma)\n",
    "        # then compute the test–train kernel\n",
    "        K_test  = rbf_kernel(X_test,  X_train, gamma=gamma)\n",
    "        X_train, X_test = K_train, K_test\n",
    "\n",
    "    # 4) Train\n",
    "    logreg = LogisticRegression(C=regularization_value, penalty='l2', max_iter=10000)\n",
    "    logreg.fit(X_train, y_train)\n",
    "\n",
    "    # 5) Predict & Evaluate\n",
    "    y_hat = logreg.predict(X_test)\n",
    "    acc   = accuracy_score(y_test, y_hat)\n",
    "    prec, rec, f1, _ = precision_recall_fscore_support(y_test, y_hat, average='binary')\n",
    "\n",
    "    return acc, prec, rec, f1\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0b38e177",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No transformation:  (0.796, 0.7037037037037037, 0.3064516129032258, 0.42696629213483145)\n",
      "Polynomial transformation:  (0.692, 0.38461538461538464, 0.4032258064516129, 0.3937007874015748)\n",
      "PCA:  (0.74, 0.42105263157894735, 0.12903225806451613, 0.19753086419753085)\n",
      "RBF Kernel:  (0.752, 0.5, 0.016129032258064516, 0.03125)\n"
     ]
    }
   ],
   "source": [
    "# No transformation\n",
    "print(\"No transformation: \", run_logistic_regression(X_train, X_test, y_train, y_test))\n",
    "\n",
    "# Example with polynomial transformation\n",
    "print(\"Polynomial transformation: \", run_logistic_regression(X_train, X_test, y_train, y_test, \n",
    "                        regularization_value=1.0, \n",
    "                        feature_method='polynomial', degree=3))\n",
    "\n",
    "# Example with PCA\n",
    "print(\"PCA: \", run_logistic_regression(X_train, X_test, y_train, y_test, \n",
    "                        regularization_value=1.0, \n",
    "                        feature_method='pca', n_components=10))\n",
    "\n",
    "# Example with RBF kernel\n",
    "print(\"RBF Kernel: \", run_logistic_regression(X_train, X_test, y_train, y_test, \n",
    "                        regularization_value=1.0, \n",
    "                        feature_method='rbf', gamma=0.5))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6351fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0564742a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "451f12ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c45a5e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
