{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0c20ba97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this will execute utils.py in your notebook’s namespace\n",
    "%run ./utils.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "efe1b6ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      ID  LIMIT_BAL  SEX  EDUCATION  MARRIAGE  AGE  PAY_0  PAY_2  PAY_3  \\\n",
      "0   2982   100000.0    1          2         1   43      1     -2     -2   \n",
      "1  12658   290000.0    1          2         1   38      0      0      0   \n",
      "2  21153   110000.0    1          2         1   48      0      0      0   \n",
      "3  26048   170000.0    2          3         1   44      0      0      0   \n",
      "4  21402   120000.0    2          2         3   59      2      2      2   \n",
      "\n",
      "   PAY_4  ...  BILL_AMT4  BILL_AMT5  BILL_AMT6  PAY_AMT1  PAY_AMT2  PAY_AMT3  \\\n",
      "0     -2  ...        0.0      551.0      551.0       0.0       0.0       0.0   \n",
      "1      0  ...    82168.0    80299.0    77324.0    3530.0    3019.0    2818.0   \n",
      "2      0  ...   136859.0    60276.0    48652.0    5000.0    4087.0   64142.0   \n",
      "3      0  ...   147611.0    28697.0   107142.0    6936.0    8266.0    5792.0   \n",
      "4      2  ...    86910.0    87893.0    86370.0       0.0    7898.0    3300.0   \n",
      "\n",
      "   PAY_AMT4  PAY_AMT5  PAY_AMT6  default.payment.next.month  \n",
      "0     551.0       0.0       0.0                           0  \n",
      "1    3000.0    3199.0    2350.0                           0  \n",
      "2    2038.0    1763.0    2500.0                           0  \n",
      "3     662.0  108927.0    4154.0                           0  \n",
      "4    3300.0       0.0    3149.0                           1  \n",
      "\n",
      "[5 rows x 25 columns]\n",
      "SVM params:\n",
      " feature_method    polynomial\n",
      "degree                     3\n",
      "n_components               5\n",
      "gamma                    0.1\n",
      "Name: 20, dtype: object \n",
      "\n",
      "Logistic Regression params:\n",
      " penalty      l2\n",
      "C          0.01\n",
      "Name: 55, dtype: object \n",
      "\n",
      "Neural Net params:\n",
      " activation                relu\n",
      "alpha                    0.001\n",
      "hidden_layer_sizes    (15, 15)\n",
      "learning_rate_init        0.01\n",
      "Name: 11, dtype: object\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pickle\n",
    "# in another notebook\n",
    "import pandas as pd\n",
    "from utils import preprocess_credit_card_data\n",
    "\n",
    "test_df = pd.read_pickle('test_df.pkl')\n",
    "print(test_df.head())\n",
    "\n",
    "# list the notebook files (relative to this notebook)\n",
    "nb_files = [\n",
    "    Path('CC_NN.ipynb'),\n",
    "    Path('CC_logistic_regression.ipynb'),\n",
    "    Path('svm') / 'CC_svm.ipynb',\n",
    "]\n",
    "\n",
    "best_models = []\n",
    "for nb in nb_files:\n",
    "    pkl = nb.with_suffix('.pkl')          # swaps .ipynb → .pkl\n",
    "    with open(pkl, 'rb') as f:\n",
    "        best_models.append(pickle.load(f))\n",
    "\n",
    "# now best_models is [best_nn_model, best_logistic_model, best_svm_model]\n",
    "nn_model = best_models[0]\n",
    "log_regr = best_models[1]\n",
    "svm = best_models[2]\n",
    "\n",
    "\n",
    "# 1) SVM (you already have this)\n",
    "svm_params = svm[['feature_method','degree','n_components','gamma']].iloc[0]\n",
    "print(\"SVM params:\\n\", svm_params, \"\\n\")\n",
    "\n",
    "# 2) Logistic Regression\n",
    "# pick the columns that correspond to your hyperparameters\n",
    "log_params = log_regr[['penalty','C']].iloc[0]\n",
    "print(\"Logistic Regression params:\\n\", log_params, \"\\n\")\n",
    "\n",
    "# 3) Neural Network\n",
    "# pick the columns that correspond to your NN hyperparameters\n",
    "nn_params = nn_model[['activation','alpha','hidden_layer_sizes','learning_rate_init']].iloc[0]\n",
    "print(\"Neural Net params:\\n\", nn_params)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "68d0c861",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.decomposition   import PCA\n",
    "from sklearn.svm             import SVC, LinearSVC\n",
    "from sklearn.linear_model    import LogisticRegression\n",
    "from sklearn.neural_network  import MLPClassifier\n",
    "from sklearn.base            import clone\n",
    "from sklearn.metrics.pairwise import rbf_kernel\n",
    "\n",
    "def test_models_on_df(models, params_list, test_df, target_col='target'):\n",
    "    \"\"\"\n",
    "    models      : list of fitted estimator objects [nn_model, log_model, svm_model]\n",
    "    params_list : list of pd.Series of hyper-params matching each model\n",
    "    test_df     : the DataFrame containing both features and the target\n",
    "    target_col  : name of the label column in test_df\n",
    "    ---\n",
    "    returns a DataFrame with columns:\n",
    "      model_name, accuracy, precision, recall, f1\n",
    "    \"\"\"\n",
    "    # split out features / target\n",
    "    y_true = test_df[target_col]\n",
    "    X      = test_df.drop(columns=[target_col])\n",
    "\n",
    "    results = []\n",
    "    for model, p in zip(models, params_list):\n",
    "        # build a fresh copy so we don't pollute the original\n",
    "        clf = clone(model)\n",
    "\n",
    "        # we need to apply the SAME feature transform that was used in training:\n",
    "        fm = p.get('feature_method', None)\n",
    "\n",
    "        if fm == 'polynomial':\n",
    "            poly = PolynomialFeatures(degree=int(p['degree']), include_bias=False)\n",
    "            X_proc = poly.fit_transform(X)\n",
    "\n",
    "        elif fm == 'pca':\n",
    "            pca = PCA(n_components=int(p['n_components']))\n",
    "            X_proc = pca.fit_transform(X)\n",
    "\n",
    "        elif fm == 'rbf':\n",
    "            # RBF: compute kernel against training “basis” from the fitted SVM\n",
    "            # we assume the saved model has a `.support_` attribute\n",
    "            X_basis = clf.support_vectors_\n",
    "            X_proc  = rbf_kernel(X, X_basis, gamma=p['gamma'])\n",
    "\n",
    "        else:\n",
    "            # linear / no extra transform\n",
    "            X_proc = X.values  # as numpy array\n",
    "\n",
    "        # now predict & score\n",
    "        y_pred = clf.predict(X_proc)\n",
    "\n",
    "        results.append({\n",
    "            'model_name':        clf.__class__.__name__,\n",
    "            'feature_method':    fm or 'linear',\n",
    "            'accuracy':          accuracy_score(y_true, y_pred),\n",
    "            'precision':         precision_score(y_true, y_pred),\n",
    "            'recall':            recall_score(y_true, y_pred),\n",
    "            'f1':                f1_score(y_true, y_pred)\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a3213fd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(250, 25)\n",
      "      ID  LIMIT_BAL  SEX  EDUCATION  MARRIAGE  AGE  PAY_0  PAY_2  PAY_3  \\\n",
      "0   2982   100000.0    1          2         1   43      1     -2     -2   \n",
      "1  12658   290000.0    1          2         1   38      0      0      0   \n",
      "2  21153   110000.0    1          2         1   48      0      0      0   \n",
      "3  26048   170000.0    2          3         1   44      0      0      0   \n",
      "4  21402   120000.0    2          2         3   59      2      2      2   \n",
      "\n",
      "   PAY_4  ...  BILL_AMT4  BILL_AMT5  BILL_AMT6  PAY_AMT1  PAY_AMT2  PAY_AMT3  \\\n",
      "0     -2  ...        0.0      551.0      551.0       0.0       0.0       0.0   \n",
      "1      0  ...    82168.0    80299.0    77324.0    3530.0    3019.0    2818.0   \n",
      "2      0  ...   136859.0    60276.0    48652.0    5000.0    4087.0   64142.0   \n",
      "3      0  ...   147611.0    28697.0   107142.0    6936.0    8266.0    5792.0   \n",
      "4      2  ...    86910.0    87893.0    86370.0       0.0    7898.0    3300.0   \n",
      "\n",
      "   PAY_AMT4  PAY_AMT5  PAY_AMT6  default.payment.next.month  \n",
      "0     551.0       0.0       0.0                           0  \n",
      "1    3000.0    3199.0    2350.0                           0  \n",
      "2    2038.0    1763.0    2500.0                           0  \n",
      "3     662.0  108927.0    4154.0                           0  \n",
      "4    3300.0       0.0    3149.0                           1  \n",
      "\n",
      "[5 rows x 25 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(test_df.shape)\n",
    "print(test_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "dc83d7ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "y_test = test_df['default.payment.next.month']\n",
    "X_test = test_df.drop(columns=['default.payment.next.month'])\n",
    "\n",
    "model_names = ['NeuralNet','LogisticReg','SVM']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f3beef9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_method    polynomial\n",
      "degree                     3\n",
      "n_components               5\n",
      "gamma                    0.1\n",
      "Name: 20, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(svm_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5299d81b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nn_model:     accuracy_validation  accuracy_train  precision_validation  \\\n",
      "11                0.728        0.973226              0.448276   \n",
      "\n",
      "    recall_validation  f1_validation  f1_train  precision_train  recall_train  \\\n",
      "11           0.419355       0.433333  0.942529         0.942529      0.942529   \n",
      "\n",
      "   activation  alpha hidden_layer_sizes  learning_rate_init  \n",
      "11       relu  0.001           (15, 15)                0.01  \n",
      "log model:    feature_method  degree  n_components  gamma  accuracy_validation  \\\n",
      "55     polynomial       3            10    0.5                0.764   \n",
      "\n",
      "    accuracy_train  precision_validation  recall_validation  f1_validation  \\\n",
      "55        0.904953              0.534884           0.370968       0.438095   \n",
      "\n",
      "    f1_train  precision_train  recall_train     C penalty  \n",
      "55  0.750877         0.963964      0.614943  0.01      l2  \n",
      "svm:    feature_method  degree  n_components  gamma  accuracy_validation  \\\n",
      "20     polynomial       3             5    0.1                 0.76   \n",
      "\n",
      "    accuracy_train  precision_validation  recall_validation  f1_validation  \\\n",
      "20        0.906292               0.52381           0.354839       0.423077   \n",
      "\n",
      "    f1_train  precision_train  recall_train      C  \n",
      "20  0.755245         0.964286       0.62069  0.001  \n"
     ]
    }
   ],
   "source": [
    "print('nn_model:', nn_model)\n",
    "print('log model:', log_regr)\n",
    "print('svm:', svm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5dc4e6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_params  = nn_model.iloc[0][['activation', 'alpha', 'hidden_layer_sizes', 'learning_rate_init']]\n",
    "log_params = log_regr.iloc[0][['penalty', 'C']]\n",
    "svm_params = svm.iloc[0][['feature_method', 'degree', 'n_components', 'gamma', 'C']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa6f7343",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Create estimators using extracted parameters\n",
    "nn_estimator = MLPClassifier(\n",
    "    hidden_layer_sizes = tuple(nn_params['hidden_layer_sizes']),\n",
    "    activation         = nn_params['activation'],\n",
    "    alpha              = nn_params['alpha'],\n",
    "    learning_rate_init = nn_params['learning_rate_init'],\n",
    "    max_iter           = 500,\n",
    "    random_state       = 42\n",
    ")\n",
    "\n",
    "log_estimator = LogisticRegression(\n",
    "    penalty = log_params['penalty'],\n",
    "    C       = log_params['C'],\n",
    "    solver  = 'liblinear' if log_params['penalty'] == 'l1' else 'lbfgs',\n",
    "    max_iter = 1000\n",
    ")\n",
    "\n",
    "svm_estimator = SVC(\n",
    "    kernel = 'poly' if svm_params['feature_method'] == 'polynomial' else 'rbf',\n",
    "    degree = int(svm_params['degree']),\n",
    "    gamma  = svm_params['gamma'],\n",
    "    C      = svm_params['C']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e028791",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Cannot clone object '    accuracy_validation  accuracy_train  precision_validation  \\\n11                0.728        0.973226              0.448276   \n\n    recall_validation  f1_validation  f1_train  precision_train  recall_train  \\\n11           0.419355       0.433333  0.942529         0.942529      0.942529   \n\n   activation  alpha hidden_layer_sizes  learning_rate_init  \n11       relu  0.001           (15, 15)                0.01  ' (type <class 'pandas.core.frame.DataFrame'>): it does not seem to be a scikit-learn estimator as it does not implement a 'get_params' method.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[62]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m df_test_results = \u001b[43mtest_models_on_df\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodels\u001b[49m\u001b[43m      \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mnn_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_regr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msvm\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparams_list\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mnn_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msvm_params\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtest_df\u001b[49m\u001b[43m     \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_df\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtarget_col\u001b[49m\u001b[43m  \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mdefault.payment.next.month\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m   \u001b[49m\u001b[38;5;66;43;03m# <— replace if your column is named differently\u001b[39;49;00m\n\u001b[32m      6\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[38;5;28mprint\u001b[39m(df_test_results)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[56]\u001b[39m\u001b[32m, line 28\u001b[39m, in \u001b[36mtest_models_on_df\u001b[39m\u001b[34m(models, params_list, test_df, target_col)\u001b[39m\n\u001b[32m     25\u001b[39m results = []\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m model, p \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(models, params_list):\n\u001b[32m     27\u001b[39m     \u001b[38;5;66;03m# build a fresh copy so we don't pollute the original\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m     clf = \u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     30\u001b[39m     \u001b[38;5;66;03m# we need to apply the SAME feature transform that was used in training:\u001b[39;00m\n\u001b[32m     31\u001b[39m     fm = p.get(\u001b[33m'\u001b[39m\u001b[33mfeature_method\u001b[39m\u001b[33m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Vai.Mathi\\Downloads\\ML-Final-Project\\.venv\\Lib\\site-packages\\sklearn\\base.py:95\u001b[39m, in \u001b[36mclone\u001b[39m\u001b[34m(estimator, safe)\u001b[39m\n\u001b[32m     93\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(estimator, \u001b[33m\"\u001b[39m\u001b[33m__sklearn_clone__\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m inspect.isclass(estimator):\n\u001b[32m     94\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m estimator.__sklearn_clone__()\n\u001b[32m---> \u001b[39m\u001b[32m95\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_clone_parametrized\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msafe\u001b[49m\u001b[43m=\u001b[49m\u001b[43msafe\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Vai.Mathi\\Downloads\\ML-Final-Project\\.venv\\Lib\\site-packages\\sklearn\\base.py:117\u001b[39m, in \u001b[36m_clone_parametrized\u001b[39m\u001b[34m(estimator, safe)\u001b[39m\n\u001b[32m    111\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[32m    112\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mCannot clone object. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    113\u001b[39m                 + \u001b[33m\"\u001b[39m\u001b[33mYou should provide an instance of \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    114\u001b[39m                 + \u001b[33m\"\u001b[39m\u001b[33mscikit-learn estimator instead of a class.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    115\u001b[39m             )\n\u001b[32m    116\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[32m    118\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mCannot clone object \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m (type \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m): \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    119\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mit does not seem to be a scikit-learn \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    120\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mestimator as it does not implement a \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    121\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[33mget_params\u001b[39m\u001b[33m'\u001b[39m\u001b[33m method.\u001b[39m\u001b[33m\"\u001b[39m % (\u001b[38;5;28mrepr\u001b[39m(estimator), \u001b[38;5;28mtype\u001b[39m(estimator))\n\u001b[32m    122\u001b[39m             )\n\u001b[32m    124\u001b[39m klass = estimator.\u001b[34m__class__\u001b[39m\n\u001b[32m    125\u001b[39m new_object_params = estimator.get_params(deep=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[31mTypeError\u001b[39m: Cannot clone object '    accuracy_validation  accuracy_train  precision_validation  \\\n11                0.728        0.973226              0.448276   \n\n    recall_validation  f1_validation  f1_train  precision_train  recall_train  \\\n11           0.419355       0.433333  0.942529         0.942529      0.942529   \n\n   activation  alpha hidden_layer_sizes  learning_rate_init  \n11       relu  0.001           (15, 15)                0.01  ' (type <class 'pandas.core.frame.DataFrame'>): it does not seem to be a scikit-learn estimator as it does not implement a 'get_params' method."
     ]
    }
   ],
   "source": [
    "nn_estimator = MLPClassifier(\n",
    "    activation         = nn_params['activation'],\n",
    "    alpha              = nn_params['alpha'],\n",
    "    hidden_layer_sizes = tuple(nn_params['hidden_layer_sizes']),\n",
    "    learning_rate_init = nn_params['learning_rate_init'],\n",
    "    max_iter           = 500,\n",
    "    random_state       = 42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfcc2f68",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
